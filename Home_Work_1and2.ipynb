{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XML2DataFrame:\n",
    "    def __init__(self, xml_path):\n",
    "        xml_data = open(xml_path)\n",
    "        self.root = ET.XML(xml_data.read())[1]\n",
    "\n",
    "    def parse_root(self, root):\n",
    "        return [self.parse_element(child) for child in iter(root)]\n",
    "\n",
    "    def parse_element(self, element, parsed=None):\n",
    "        if parsed is None:\n",
    "            parsed = dict()\n",
    "        for key in element.keys():\n",
    "            parsed[key] = element.attrib.get(key)\n",
    "        if element.text:\n",
    "            parsed[element.attrib[\"name\"]] = None if element.text == \"NULL\" else element.text\n",
    "        for child in list(element):\n",
    "            self.parse_element(child, parsed)\n",
    "        return parsed\n",
    "\n",
    "    def process_data(self):\n",
    "        structure_data = self.parse_root(self.root)\n",
    "        return pd.DataFrame(structure_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = XML2DataFrame(\"tkk_train_2016.xml\").process_data().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train[\"text\"].values\n",
    "train_labels = train[[\"beeline\", \"komstar\", \"mts\", \"rostelecom\", \"skylink\", \"tele2\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mkomov Максим, Вашем письмо мы получили. Наши сотрудники свяжутся с Вами завтра и направят запрос инженерам для проверки. #билайн',\n",
       "       '«Мегафон» стал владельцем 50% акций «Евросети»',\n",
       "       'RT @fuckkiev: “@EvaKobb: МТС Россия прислала жителям Херсонщины сообщения, в которых обозвала украинцев фашистами? http://t.co/RbSesXlOUZ” …',\n",
       "       ...,\n",
       "       'RT @Olympialeigh: У МТС проблемы со связью из-за замены оборудования',\n",
       "       'RT @ManisaMerkez45: У МТС проблемы со связью из-за замены оборудования',\n",
       "       'RT @MertKaraoban: У МТС проблемы со связью из-за замены оборудования'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = XML2DataFrame(\"tkk_test_etalon.xml\").process_data().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test[\"text\"].values\n",
    "test_labels = test[[\"beeline\", \"komstar\", \"mts\", \"rostelecom\", \"skylink\", \"tele2\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = []\n",
    "for string in train_labels:\n",
    "    new_labels.append(sum([int(val) for val in string]))\n",
    "    if new_labels[-1]<-1:\n",
    "        new_labels[-1]=-1\n",
    "    elif new_labels[-1]>1:\n",
    "        new_labels[-1]=1\n",
    "train_labels = new_labels\n",
    "\n",
    "new_labels = []\n",
    "for string in test_labels:\n",
    "    new_labels.append(sum([int(val) for val in string]))\n",
    "    if new_labels[-1]<-1:\n",
    "        new_labels[-1]=-1\n",
    "    elif new_labels[-1]>1:\n",
    "        new_labels[-1]=1\n",
    "test_labels=new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=7,random_state=42,verbose=1,warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python/venv3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 7.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=7,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(tfidf.transform(train_texts), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list(lr.predict(tfidf.transform(test_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4542176544883651\n",
      "0.654650645304851\n"
     ]
    }
   ],
   "source": [
    "# With no regularization except L2\n",
    "print(f1_score(test_labels,pred, average='macro'))\n",
    "print(f1_score(test_labels,pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = tfidf.transform(train_texts).toarray()\n",
    "test_tfidf = tfidf.transform(test_texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_reg = np.array([(string-string.mean())/string.std() for string in train_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf_reg = np.array([(string-string.mean())/string.std() for string in test_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=3,random_state=42,verbose=1,warm_start=True,max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python/venv3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=3,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_tfidf_reg, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_reg = list(lr.predict(test_tfidf_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5266087980476643\n",
      "0.6444147752558967\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_labels,pred_reg,average='macro'))\n",
    "print(f1_score(test_labels,pred_reg,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results at SentiRueval2016: <br>\n",
    "F1_macro = 0.5493 <br>\n",
    "F1_micro = 0.6822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banks analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banks = XML2DataFrame('bank_train_2016.xml').process_data().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_banks = XML2DataFrame('banks_test_etalon.xml').process_data().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banks_texts = train_banks['text'].values\n",
    "train_banks_labels = train_banks[[\n",
    "    \"sberbank\", \"vtb\", \"gazprom\", \"alfabank\", \"bankmoskvy\", \"raiffeisen\",\n",
    "    \"uralsib\", \"rshb\"\n",
    "]].values\n",
    "new_labels = []\n",
    "for string in train_banks_labels:\n",
    "    new_labels.append(sum([int(val) for val in string]))\n",
    "    if new_labels[-1]<-1:\n",
    "        new_labels[-1]=-1\n",
    "    elif new_labels[-1]>1:\n",
    "        new_labels[-1]=1\n",
    "train_banks_labels = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_banks_texts = test_banks['text'].values\n",
    "test_banks_labels = test_banks[[\n",
    "    \"sberbank\", \"vtb\", \"gazprom\", \"alfabank\", \"bankmoskvy\", \"raiffeisen\",\n",
    "    \"uralsib\", \"rshb\"\n",
    "]].values\n",
    "new_labels = []\n",
    "for string in test_banks_labels:\n",
    "    new_labels.append(sum([int(val) for val in string]))\n",
    "    if new_labels[-1]<-1:\n",
    "        new_labels[-1]=-1\n",
    "    elif new_labels[-1]>1:\n",
    "        new_labels[-1]=1\n",
    "test_banks_labels = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=3,random_state=42,verbose=1,warm_start=True,max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_banks = vectorizer.fit(train_banks_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banks_tfidf = tfidf_banks.transform(train_banks_texts).toarray()\n",
    "test_banks_tfidf = tfidf_banks.transform(test_banks_texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python/venv3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=3,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_banks_tfidf,train_banks_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banks results with no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks_pred = list(lr.predict(test_banks_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4979622045828058\n",
      "0.73407787503773\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(banks_pred,test_banks_labels,average='macro'))\n",
    "print(f1_score(banks_pred,test_banks_labels,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization for banks tf/idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_banks_tfidf_reg = np.array([(string-string.mean())/string.std() for string in train_banks_tfidf])\n",
    "test_banks_tfidf_reg = np.array([(string-string.mean())/string.std() for string in test_banks_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=3,random_state=42,verbose=1,warm_start=True,max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python/venv3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=3,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_banks_tfidf_reg,train_banks_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for banks with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks_pred_reg = list(lr.predict(test_banks_tfidf_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29355505573876134\n",
      "0.7214005433142169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python/venv3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(banks_pred_reg,test_banks_labels,average='macro'))\n",
    "print(f1_score(banks_pred_reg,test_banks_labels,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=3,random_state=42,verbose=1,warm_start=True,max_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all train tweets for both banks and tkk with logreg and no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_labels = train_banks_labels\n",
    "total_train_labels.extend(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_texts = []\n",
    "total_train_texts.extend(train_banks_texts)\n",
    "total_train_texts.extend(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tfidf = vectorizer.fit(total_train_texts)\n",
    "total_train_tfidf = total_tfidf.transform(total_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python/venv3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=3,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(total_train_tfidf,total_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for test_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_pred = list(lr.predict(total_tfidf.transform(test_banks_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5382323874148384\n",
      "0.7524901901599759\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(tot_pred,test_banks_labels,average='macro'))\n",
    "print(f1_score(tot_pred,test_banks_labels,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results at SentiRueval2016: <br>\n",
    "F1_macro = 0.5252 <br>\n",
    "F1_micro = 0.5881"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for test_tkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_pred = list(lr.predict(total_tfidf.transform(test_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4802356659930958\n",
      "0.6653315531820204\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(tot_pred,test_labels,average='macro'))\n",
    "print(f1_score(tot_pred,test_labels,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results at SentiRueval2016: <br>\n",
    "F1_macro = 0.5493 <br>\n",
    "F1_micro = 0.6813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Embedding, Dropout, Dense, GlobalAveragePooling1D, MaxPooling1D, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size= 50\n",
    "lang_model = FastText(min_count=1,window=5,workers=7,size=size)\n",
    "prepared_for_embed = [sent.split() for sent in total_train_texts]\n",
    "lang_model.build_vocab(prepared_for_embed)\n",
    "lang_model.train(prepared_for_embed, total_examples=lang_model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "seq_length=30\n",
    "model.add(Conv1D(64, 10, activation='relu',input_shape=(seq_length, size)))\n",
    "model.add(MaxPooling1D(10))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18035 samples, validate on 3313 samples\n",
      "Epoch 1/10\n",
      "18035/18035 [==============================] - 1s 40us/step - loss: 0.7015 - acc: 0.6923 - f1: 0.6937 - val_loss: 0.7684 - val_acc: 0.6788 - val_f1: 0.7082\n",
      "Epoch 2/10\n",
      "18035/18035 [==============================] - 0s 21us/step - loss: 0.6625 - acc: 0.7037 - f1: 0.7135 - val_loss: 0.7672 - val_acc: 0.6828 - val_f1: 0.7000\n",
      "Epoch 3/10\n",
      "18035/18035 [==============================] - 0s 21us/step - loss: 0.6542 - acc: 0.7054 - f1: 0.7181 - val_loss: 0.7621 - val_acc: 0.6782 - val_f1: 0.7058\n",
      "Epoch 4/10\n",
      "18035/18035 [==============================] - 0s 21us/step - loss: 0.6446 - acc: 0.7154 - f1: 0.7244 - val_loss: 0.7618 - val_acc: 0.6873 - val_f1: 0.7061\n",
      "Epoch 5/10\n",
      "18035/18035 [==============================] - 0s 21us/step - loss: 0.6336 - acc: 0.7222 - f1: 0.7314 - val_loss: 0.7725 - val_acc: 0.6912 - val_f1: 0.7008\n",
      "Epoch 6/10\n",
      "18035/18035 [==============================] - 0s 21us/step - loss: 0.6272 - acc: 0.7278 - f1: 0.7340 - val_loss: 0.7639 - val_acc: 0.6867 - val_f1: 0.7078\n",
      "Epoch 7/10\n",
      "18035/18035 [==============================] - 0s 24us/step - loss: 0.6198 - acc: 0.7310 - f1: 0.7355 - val_loss: 0.7591 - val_acc: 0.6909 - val_f1: 0.7074\n",
      "Epoch 8/10\n",
      "18035/18035 [==============================] - 0s 24us/step - loss: 0.6140 - acc: 0.7310 - f1: 0.7389 - val_loss: 0.7602 - val_acc: 0.6936 - val_f1: 0.7093\n",
      "Epoch 9/10\n",
      "18035/18035 [==============================] - 0s 21us/step - loss: 0.6113 - acc: 0.7327 - f1: 0.7398 - val_loss: 0.7557 - val_acc: 0.6894 - val_f1: 0.7094\n",
      "Epoch 10/10\n",
      "18035/18035 [==============================] - 0s 24us/step - loss: 0.6090 - acc: 0.7346 - f1: 0.7421 - val_loss: 0.7554 - val_acc: 0.6924 - val_f1: 0.7111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84f8322278>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded, get_dummies(total_train_labels).values, validation_data=(test_banks_padded, get_dummies(test_banks_labels).values), batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred = model.predict(test_banks_padded)\n",
    "cnn_pred_val = [np.argmax(string)-1 for string in cnn_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42798596045027865\n",
      "0.7060066405070933\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(cnn_pred_val,test_banks_labels, average='macro'))\n",
    "print(f1_score(cnn_pred_val,test_banks_labels, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred = model.predict(test_tkk_padded)\n",
    "cnn_pred_val = [np.argmax(string)-1 for string in cnn_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35845707364251805\n",
      "0.5571873609256787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python/venv3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(cnn_pred_val,test_labels, average='macro'))\n",
    "print(f1_score(cnn_pred_val,test_labels, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs = np.array([lang_model.wv[sent] for sent in prepared_for_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "size= 50\n",
    "padded = pad_sequences(wvs,padding='post', value=np.full(size,0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_banks_wvs = []\n",
    "for sent in test_banks_texts:\n",
    "    prep_sent = []\n",
    "    for word in sent.split():\n",
    "        try:\n",
    "            prep_sent.append(lang_model.wv[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    test_banks_wvs.append(np.array(prep_sent))\n",
    "test_banks_wvs = np.array(test_banks_wvs)\n",
    "\n",
    "test_banks_padded = pad_sequences(test_banks_wvs,padding='post', maxlen=30, value=np.full(size,0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro_from_dummies(pred,gt, average='macro'):\n",
    "    gt_val = [np.argmax(string)-1 for string in gt]\n",
    "    pred_val = [np.argmax(string)-1 for string in pred]\n",
    "    return mean(np.array([f1_score(gt_val, pred_val, average=average)]))\n",
    "def f1_micro_from_dummies(pred,gt, average='micro'):\n",
    "    gt_val = [np.argmax(string)-1 for string in gt]\n",
    "    pred_val = [np.argmax(string)-1 for string in pred]\n",
    "    return mean(np.array([f1_score(gt_val, pred_val, average=average)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tkk_wvs = []\n",
    "for sent in test_texts:\n",
    "    prep_sent = []\n",
    "    for word in sent.split():\n",
    "        try:\n",
    "            prep_sent.append(lang_model.wv[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    test_tkk_wvs.append(np.array(prep_sent))\n",
    "test_tkk_wvs = np.array(test_tkk_wvs)\n",
    "\n",
    "test_tkk_padded = pad_sequences(test_tkk_wvs,padding='post', maxlen=30, value=np.full(size,0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42798596045027865"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7060066405070933"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.dtype' object has no attribute 'base_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-2429a3808d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_macro_from_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_banks_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-b0175baeef37>\u001b[0m in \u001b[0;36mf1_macro_from_dummies\u001b[0;34m(pred, gt, average)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgt_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1_micro_from_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mgt_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/python/venv3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmean\u001b[0m \u001b[0mof\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \"\"\"\n\u001b[0;32m-> 1379\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.dtype' object has no attribute 'base_dtype'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true,y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return (precision+recall+K.epsilon())/(2*((precision*recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
